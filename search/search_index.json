{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p><code>coproc</code> provides building blocks for running stateful, concurrent, and specialized worker processes that require back-and-forth communication. The name comes from the combination of \"cooperative\" and \"process\" - <code>coproc</code> makes it easier to create specialized processes that cooperate to solve a single task.</p>"},{"location":"#design","title":"Design","text":"<ul> <li> <p>In <code>coproc</code>, we refer to the main process of a Python script as the host, and any daeomon processes it creates as worker processes. </p> </li> <li> <p>The host maintains a <code>WorkerResource</code> object which includes the child process and a pipe for transmitting information, as well as a <code>PriorityMessenger</code> that manages communications across the channel. </p> </li> <li> <p><code>WorkerProcess</code> exists on the worker side, and maintains the processes state and main event loop. The worker process also includes a <code>PriorityMessenger</code> that is used to communicate with the host process.</p> </li> </ul> <p>The following diagram shows how the host and worker work together: they each maintain <code>PriorityMessenger</code> objects that support multi-channel priority messaging designs.</p>"},{"location":"building_blocks/","title":"Building Blocks","text":"<p><code>coproc</code> is essentially a set of building blocks for working with processes. Here I demonstrate how these objects work together. See the documentation for more elaborate explanations.</p> <ul> <li> <p><code>WorkerResource</code>: manage concurrent processes and the pipes they use to communicate using a messenger. See examples/introduction.ipynb for more.</p> </li> <li> <p><code>PriorityMessenger</code>: used by worker resource to manage multi-channel priority queues for communication between processes. See examples/messenger_introduction.ipynb for more.</p> </li> <li> <p><code>WorkerResourcePool</code>: maintains set of identical worker resources that can process data in a way that is similar to <code>multiprocessing.Pool</code>.</p> </li> </ul>"},{"location":"building_blocks/#high-level-objects","title":"High-level objects:","text":"<ul> <li><code>Monitor</code>: create concurrent process for monitoring and reporting on other processes. Write to logs, generate reports, and </li> </ul>"},{"location":"building_blocks/#workerresource-and-prioritymessenger-examples","title":"<code>WorkerResource</code> and <code>PriorityMessenger</code> Examples","text":"<p>Use <code>WorkerResource</code> to manage a single concurrent process. In this example, <code>EchoProcess</code> simply echoes back received data.</p> <pre><code>import dataclasses\n\n@dataclasses.dataclass\nclass EchoProcess(coproc.BaseWorkerProcess):\n    '''Simply echoes back received data.'''\n    verbose: bool = False\n    def __call__(self):\n        while True:\n            try:\n                data = self.messenger.receive_blocking()\n            except coproc.ResourceRequestedClose:\n                break\n\n            if self.verbose: print(f'EchoProcess received: {data}')\n\n            self.messenger.send_reply(data)\n\n            if self.verbose: print(f'EchoProcess sent: {data}')\n\nwith coproc.WorkerResource(EchoProcess) as worker:\n    worker.messenger.send_request('Hello, world!')\n    print(worker.messenger.receive_blocking())\n\n</code></pre> <p>Instead of using <code>WorkerResource</code>'s context manager, you can also use <code>WorkerResource.start()</code> and <code>WorkerResource.terminate()</code> directly within a custom object.</p> <pre><code>@dataclasses.dataclass\nclass EchoResource:\n    verbose: bool = False\n    resource: coproc.WorkerResource = dataclasses.field(default_factory=lambda: coproc.WorkerResource(EchoProcess))\n\n    def __enter__(self) -&gt; coproc.PriorityMessenger:\n        self.resource.start(verbose=self.verbose)\n        return self\n\n    def __exit__(self, *args):\n        self.resource.terminate()\n\n    def apply(self, data):\n        self.messenger.send_request(data)\n        return self.messenger.receive_blocking()\n\n    @property\n    def messenger(self):\n        return self.resource.messenger\n\nwith EchoResource(verbose=True) as w:\n    print(w.apply('Hello, world!'))\n\n</code></pre>"},{"location":"building_blocks/#monitor-examples","title":"<code>Monitor</code> Examples","text":"<pre><code>import multiprocessing\nimport tqdm\n\nmonitor = coproc.Monitor(\n    snapshot_seconds=0.01, \n    fig_path='tmp/test_parallel.png',\n    log_path='tmp/test_parallel.log'\n)\n\nwith monitor as m:\n    time.sleep(0.1)\n    m.add_note('starting workers')\n    with multiprocessing.Pool(4) as p:\n        m.update_child_processes()\n        p.map(test_thread, [1e5, 2e5, 3e5, 4e5])\n\n    m.add_note('finished workers')\n\n    l = list()\n    for i in tqdm.tqdm(range(int(1e8)), ncols=80):\n        l.append(i)\n        if i &gt; 0 and i % int(3e7) == 0:\n            m.add_note('emptying list', 'dumping all memory', do_print=False)\n            l = list()\n\n    stats = m.get_stats()\nstats.save_memory_plot('tmp/test_parallel.png', font_size=8)\n\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p><code>coproc</code> is not currently on PyPI. Install coproc from the following repository:</p> <p><code>pip install --upgrade git+https://github.com/devincornell/coproc.git@main</code></p>"},{"location":"documentation/introduction/","title":"Overview","text":"<p>In this notebook, I demonstrate use of the most basic building blocks of <code>conproc</code>: <code>WorkerResource</code> and <code>PriorityQueue</code>.</p> <pre><code>import sys\nsys.path.append('../')\nimport coproc\n</code></pre>"},{"location":"documentation/introduction/#workerresource-and-managing-worker-processes","title":"<code>WorkerResource</code> and Managing Worker Processes","text":"<p>The <code>WorkerResource</code> object is the most basic tool for working with concurrent processes. It manages both <code>Process</code> and <code>Pipe</code> objects wrapped in multi-channel priority queues with robust messaging support. The most common use case is to create a <code>WorkerResource</code> object and then manage the resource using a wrapper object. While it does have a built-in context manager for starting and ending the process, you will probably want to create your own outer context manager using the basic <code>.start()</code>, <code>.stop()</code>, and <code>.join()</code> methods.</p> <p>The <code>WorkerResource</code> constructor accepts a class that is used to manage the process. That class' <code>__init__</code> method will be called in the host process with a single <code>PriorityMessenger</code> argument, and you may pass additional keyword arguments through the <code>.start()</code> method. The resulting instance will then be passed to the process for the duration of the <code>__call__</code> method, which does not accept any arguments on its own - you must pass any relevant data through the constructor when starting the process.</p> <p>The following class maintains the state of an example worker process. As long as it is alive, it will simply receive data and echo the data back to the host process. Notice that <code>__init__</code> accepts the messenger and an additional optional parameter. The messenger is passed automatically, whereas the keyword arguments are passed through the <code>.start()</code> method. I will discuss the <code>.receive_blocking()</code> and <code>.send_norequest()</code> methods in more detail later in the messaging section.</p> <pre><code>import os\n\nclass CustomEchoProcess:\n    '''This object represents the spawned process.'''\n\n    def __init__(self, messenger: coproc.PriorityMessenger, verbose: bool = False):\n        '''Called on the host process to initialize the worker process before passing to worker.'''\n        self.messenger = messenger\n        self.verbose = verbose\n\n    def __call__(self):\n        '''Main process loop.'''\n        if self.verbose: print(f'Starting process {os.getpid()}')\n\n        while True:\n            # wait until a new message is received\n            data = self.messenger.receive_blocking()\n            print(f'process {os.getpid()} received: {data}')\n\n            # send the same data back\n            self.messenger.send_norequest(data)\n\nresource = coproc.WorkerResource(CustomEchoProcess)\nresource\n</code></pre> <pre><code>WorkerResource(worker_process_type=&lt;class '__main__.CustomEchoProcess'&gt;, method=None, _proc=None, _messenger=None)\n</code></pre> <p>You can see here that the <code>verbose</code> argument is passed through start.</p> <pre><code>import time\n\nresource.start(verbose=True)\ntime.sleep(0.1)\nresource.terminate()\n\n# wait for process to terminate\nwhile resource.is_alive():\n    pass\n\nresource.start()\ntime.sleep(0.1)\nresource.terminate()\n</code></pre> <pre><code>Starting process 878039\n</code></pre>"},{"location":"documentation/introduction/#inherit-from-baseworkerprocess","title":"Inherit from <code>BaseWorkerProcess</code>","text":"<p>For convenience, we can inherit from the dataclass <code>BaseWorkerProcess</code> which includes a <code>PriorityMessenger</code> argument in its <code>__init__</code> method. This is not required, but makes smaller classes. Dataclasses are generally pretty useful in these scenarios because you'll need to pass everything through the constructor anyway.</p> <pre><code>import dataclasses\n\n@dataclasses.dataclass\nclass TempProcess(coproc.BaseWorkerProcess):\n    verbose: bool = False\n\n    def __call__(self):\n        if self.verbose: print(f'Starting process {os.getpid()}')\n        if self.verbose: print(f'Process {os.getpid()} is ending.')\n</code></pre>"},{"location":"documentation/introduction/#context-managers","title":"Context Managers","text":"<p>The resource should always be used in some type of context manager, and we can use the built-in context manager for simple applications. The downside to this is that you cannot pass any arguments to <code>.start()</code>.</p> <pre><code>with coproc.WorkerResource(CustomEchoProcess) as w:\n    print(type(w))\n</code></pre> <pre><code>&lt;class 'coproc.workerresource.WorkerResource'&gt;\n</code></pre> <p>Typically it will be better to create your own wrapper objects for cleaner interfaces. Here I use a dataclass that creates a <code>WorkerResource</code> in the constructor and provide the most basic context management.</p> <pre><code>import dataclasses\n\n@dataclasses.dataclass\nclass EchoResource:\n    verbose: bool = False\n    resource: coproc.WorkerResource = dataclasses.field(default_factory=lambda: coproc.WorkerResource(CustomEchoProcess))\n\n    def __enter__(self) -&gt; coproc.PriorityMessenger:\n        self.resource.start(verbose=self.verbose)\n        return self.resource\n\n    def __exit__(self, *args):\n        self.resource.terminate()\n\nwith EchoResource(verbose=True) as w:\n    print(w)\n</code></pre> <pre><code>WorkerResource(worker_process_type=&lt;class '__main__.CustomEchoProcess'&gt;, method=None, _proc=&lt;ForkProcess name='ForkProcess-4' pid=878049 parent=878005 started&gt;, _messenger=PriorityMessenger(pipe=&lt;multiprocessing.connection.Connection object at 0x7ff775d0a4f0&gt;, queue=PriorityMultiQueue(pqueues={}), request_ctr=RequestCtr(requests=Counter(), replies=Counter())))\n</code></pre>"},{"location":"documentation/introduction/#messaging-between-processes-prioritymessenger-and-multimessenger","title":"Messaging Between Processes: <code>PriorityMessenger</code> and <code>MultiMessenger</code>","text":"<p>The <code>coproc</code> messengers are wrappers around standard <code>multiprocessing.Pipe</code> objects that create an interface for exchange between processes. There are two primary messenger types that can be used for communications: <code>PriorityMessenger</code> and <code>MultiMessenger</code>. While they both support the request and channel interfaces, only <code>PriorityMessenger</code> supports priorities, as the name would imply. </p>"},{"location":"documentation/introduction/#sending-messages","title":"Sending Messages","text":"<p>Basic communication.     + <code>send_norequest()</code> sends a message without expecting a reply. This is the most basic method for sending data between processes. Specify <code>channel_id</code> to send to a specific channel (<code>None</code> by default, which is actually a valid channel). The simplest use of messager would be to to send messages back and forth using <code>send_norequest()</code>. This is most similar to <code>pipe.send()</code> and <code>pipe.recv()</code> except that it manages multiple channels (see next section).</p> <ol> <li> <p>Channels. Every message is associated with a channel, which can be any hashable object. </p> <ul> <li>You can specify the channel using the <code>channel_id</code> parameter of most send/receive functions, and the default is <code>None</code> - itself a valid, hashable channel id which you may use by default.</li> </ul> </li> <li> <p>Requests. Using special request and reply methods enables the messenger to track the number of requests sent and replies received so that it can wait for replies to a specific set of requests.</p> <ul> <li>The requesting process would use <code>send_request()</code> to send a request, and the other process would use <code>send_reply()</code> so that the requesting process knows that the message is a reply.</li> <li>Note that the request tracking happens on a per-channel basis, so you can send multiple requests on different channels and wait for replies to each set of requests.</li> <li><code>send_request()</code> will send a message while also incrementing the count of requested messages for the given channel.</li> <li><code>send_reply()</code> will send a message while also incrementing the count of received replies for the recipient channel.</li> </ul> </li> <li> <p>Priorities. By default, the <code>PriorityMessenger</code> looks for a <code>priority</code> attribute on any messages being sent, and will sort the messages into a priority queue, rather than a standard fifo queue. If the sent item does not have this attribute, by default it is set to <code>-inf</code>.</p> </li> <li> <p>Special Messages. There are several types of special messages that bypass the channel and priority queue interface - they are handled as soon as the messages are received (which occurs when any receive function is called), prior to placement in the queue.</p> <ul> <li><code>send_error()</code> will send an exception object to the other messenger that will then be raised directly in the recipient process. I recommend using custom exceptions for this behavior.</li> <li><code>send_close_request()</code> will send a message that directly raises a <code>ResourceRequestedClose</code> exception in the recipient process. Catch this exception in your processes to handle a shutdown. You may want to use this in conjunction with the <code>.join()</code> method, which waits for the process to finish.</li> </ul> </li> </ol>"},{"location":"documentation/introduction/#receiving-messages","title":"Receiving Messages","text":"<p>Any time one of the following receive methods is called, data will be transferred from the <code>multiprocessing.Pipe</code> into the message queue. The following diagram shows the basic flow of data from the pipe to the receive methods.</p> <p></p> <p>The receive method you use depends on the desigred behavior.</p> <ul> <li><code>available()</code> loads data from pipe into the queue, and returns the number of available messages on the specified channel. </li> <li><code>receive_available()</code> calls <code>available()</code> and returns all available messages if there are any. Otherwise, returns an empty list.</li> <li><code>receive_blocking()</code> blocks until a message is received on the specified channel, then returns the message.</li> <li><code>receive_remaining()</code> yields replies on the specified channel until all outstanding requests have been replied to.</li> </ul> <pre><code>with EchoResource(verbose=True) as w:\n    w.messenger.send_norequest('hello')\n    print(w.messenger.receive_blocking())\n</code></pre> <pre><code>Starting process 878050\nprocess 878050 received: hello\nhello\n</code></pre>"},{"location":"documentation/introduction/#requests","title":"Requests","text":"<p>The messenger also has support for handling messages that act as requests and replies. Alternatively, you may use a combination of <code>.send_request</code> (on the host side) and <code>.send_reply</code> (on the worker side) to send requests that are expected to have replies. You can check the number of remaining messages using <code>.remaining()</code>, and call <code>.receive_remaining()</code> to block while retrieving all remaining messages. You, the client, must manually manage the request-reply pattern, but this is intended to be used as a way of keeping track of how many messages are expected to be received.</p> <pre><code>@dataclasses.dataclass\nclass EchoProcess1(coproc.BaseWorkerProcess):\n    def __call__(self):\n        while True:\n            data = self.messenger.receive_blocking()\n            self.messenger.send_reply(data)\n\nwith coproc.WorkerResource(EchoProcess1) as w:\n    print(w.messenger.remaining())\n    w.messenger.send_request('hello')\n    print(w.messenger.remaining())\n    print(w.messenger.receive_blocking())\n    print(w.messenger.remaining())\n\n    [w.messenger.send_request(i) for i in range(3)]\n    w.messenger.remaining()\n    for d in w.messenger.receive_remaining():\n        print(d)\n</code></pre> <pre><code>0\n1\nhello\n0\n0\n1\n2\n</code></pre>"},{"location":"documentation/introduction/#message-availability","title":"Message Availability","text":"<p>When juggling between receiving messages and other tasks, it is often helpful to retrieve all messages that are available in the queue at a given point in time. Check how many messages have been received using <code>.available()</code> and retrieve available messages using <code>.receive_available()</code> instead of <code>.receive_blocking()</code>.</p> <pre><code>with coproc.WorkerResource(EchoProcess1) as w:\n    print(w.messenger.available())\n    w.messenger.send_request('hello')\n    print(w.messenger.available())\n    time.sleep(0.1) # wait for process to reply\n    print(w.messenger.available())\n    print(w.messenger.receive_available())\n</code></pre> <pre><code>0\n0\n1\n['hello']\n</code></pre>"},{"location":"documentation/introduction/#custom-messages-and-priorities","title":"Custom Messages and Priorities","text":"<p>The <code>PriorityMessenger</code> includes a priority system which you can use by creating custom message types. It determines the priority of a message by looking for a <code>priority</code> attribute on the data being passed. Here I create two types of messages, each with a different priority - note that lower priority value means it will be returned first. This follows the behavior of the <code>queue.PriorityQueue</code>.</p> <pre><code>@dataclasses.dataclass\nclass WarningMessage:\n    message: str\n    priority: int = 0 # higher priority\n\n@dataclasses.dataclass\nclass DataMessage:\n    data: int\n    priority: int = 1 # lower priority\n\n@dataclasses.dataclass\nclass EchoProcess2(coproc.BaseWorkerProcess):\n    def __call__(self):\n        while True:\n            num = self.messenger.receive_blocking()\n            self.messenger.send_reply(DataMessage(num))\n            if num &lt; 0:\n                self.messenger.send_norequest(WarningMessage('negative number'))\n\nwith coproc.WorkerResource(EchoProcess2) as w:\n    w.messenger.send_request(1)\n    time.sleep(0.1)\n    print(w.messenger.receive_available())\n\n    # notice the warning appears in the queue first\n    w.messenger.send_request(-1)\n    time.sleep(0.1)\n    print(w.messenger.receive_available())\n</code></pre> <pre><code>[DataMessage(data=1, priority=1)]\n[WarningMessage(message='negative number', priority=0), DataMessage(data=-1, priority=1)]\n</code></pre>"},{"location":"documentation/introduction/#message-channels","title":"Message Channels","text":"<p>In more complicated situations, there may be cases when you want to communicate on separate messaging channels. Fortunately, <code>PriorityMessenger</code> can also handle that, as most methods accept a <code>channel_id</code> parameter that is defaulted to <code>None</code>. The <code>channel_id</code> can be any hashable object, so <code>None</code> is actually the channel being communicated on for most of the previous examples. Each channel keeps track of its own request/receive counts, and each can make a blocking receive until they receive the expected message. In this way, the channels essentially operate as separate pipes.</p> <p>In the following example, I use a single channel for data sent from the host to the client process, and two channels for data sent from the client to the host. Whereas the <code>DATA</code> channel is used to transmit regular data synchronously between the processes, <code>WARNING</code> is used to transmit data asynchronously from the client process to the host. Note that we use the same channel for the bidirectional communication from the host to the client process because we are taking advantage of the request interface.</p> <pre><code>import enum\nclass Channels(enum.Enum):\n    DATA = 1\n    WARNING = 2\n\n@dataclasses.dataclass\nclass EchoProcess3(coproc.BaseWorkerProcess):\n    def __call__(self):\n        while True:\n            try:\n                data = self.messenger.receive_blocking(Channels.DATA)\n            except coproc.ResourceRequestedClose:\n                break\n\n            if len(data) &lt; 10:\n                # send a message on the warning channel\n                self.messenger.send_norequest(f'warning: data must be positive', Channels.WARNING)\n\n            # either way, echo result\n            self.messenger.send_reply(data, Channels.DATA)\n\n\ndef receive_print_warnings(message: str, messenger: coproc.PriorityMessenger) -&gt; str:\n    messenger.send_request(message, Channels.DATA)\n    print(f'{messenger.remaining(Channels.DATA)=}')\n\n    data = messenger.receive_blocking(Channels.DATA)\n    print(f'{messenger.remaining(Channels.DATA)=}')\n\n    for warning in messenger.receive_available(Channels.WARNING):\n        print(warning)\n\n    return data\n\nwith coproc.WorkerResource(EchoProcess3) as w:\n    print(receive_print_warnings('hello', w.messenger))\n    print(receive_print_warnings('world', w.messenger))\n    print(receive_print_warnings('hello world!', w.messenger))\n</code></pre> <pre><code>messenger.remaining(Channels.DATA)=1\nmessenger.remaining(Channels.DATA)=0\nwarning: data must be positive\nhello\nmessenger.remaining(Channels.DATA)=1\nmessenger.remaining(Channels.DATA)=0\nwarning: data must be positive\nworld\nmessenger.remaining(Channels.DATA)=1\nmessenger.remaining(Channels.DATA)=0\nhello world!\n</code></pre>"},{"location":"documentation/introduction/#system-messages","title":"System Messages","text":"<p>There are two special types of messages that will be prioritized over all other messages: sending errors using <code>send_error()</code> (typically sent from worker process) and sending a termination signal using <code>send_close_request()</code> (typically sent by the host process). The <code>send_error()</code> message will send a signal that raises the sent exception on the client side, and <code>send_close_request()</code> will raise a <code>ResourceRequestedClose</code> exception on the worker side. You will need to handle these cases on both sides of the pipe.</p> <pre><code>@dataclasses.dataclass\nclass EchoProcess4(coproc.BaseWorkerProcess):\n    def __call__(self):\n        while True:\n            try:\n                data = self.messenger.receive_blocking()\n            except coproc.ResourceRequestedClose:\n                break            \n            if data &gt;= 0:\n                self.messenger.send_reply(data)\n            else:\n                self.messenger.send_error(ValueError('data must be positive'))\n\nwith coproc.WorkerResource(EchoProcess4) as w:\n\n    # regular request/reply\n    w.messenger.send_request(1)\n    print(w.messenger.receive_blocking())\n\n    # this request will elicit an error\n    w.messenger.send_request(-1)\n    try:\n        print(w.messenger.receive_blocking())\n    except ValueError as e:\n        print(type(e), e)\n\n    w.messenger.send_close_request()\n    w.join()\n    time.sleep(0.5)\n    print(w.is_alive())\n</code></pre> <pre><code>NoneType: None\n\n\n1\n&lt;class 'ValueError'&gt; data must be positive\nFalse\n</code></pre> <p><code>WorkerResource</code> and <code>PriorityMessenger</code> serve as essential building blocks for building interfaces to concurrent processes, including some that appear as part of this package. See the documentation for examples of those.</p>"},{"location":"documentation/introduction/#an-inspirational-example","title":"An Inspirational Example","text":"<p>The following example shows a process dedicated to controlling a process which prints to the screen. It is a particularly good example because it does something that would not be possible in a single process nor using map functions as part of the multiprocessing package.</p> <pre><code>@dataclasses.dataclass\nclass StartPrinting:\n    pass\n\n@dataclasses.dataclass\nclass StopPrinting:\n    pass\n\n@dataclasses.dataclass\nclass ChangePrintBehavior:\n    print_frequency: int\n    print_char: str\n\n@dataclasses.dataclass\nclass Receipt:\n    pass\n</code></pre> <pre><code>class AlreadyPrintingError(Exception):\n    '''Raised when user requests start but process is already printing.'''\n\nclass AlreadyNotPrintingError(Exception):\n    '''Raised when user requests stop but process is already not printing.'''\n</code></pre> <pre><code>import typing\n\n@dataclasses.dataclass\nclass PrintingProcess:\n    messenger: coproc.PriorityMessenger # every process must accept this\n    print_frequency: int # these must be set at worker start\n    print_char: str\n    keep_printing: bool # this can optionally be set\n\n    def __call__(self):\n        print(f'{self.keep_printing=}')\n        while True:\n            try:\n                # if we're not printing, keep waiting for a new message\n                msgs = self.messenger.receive_available()#blocking = not self.keep_printing)\n            except IndexError:\n                msgs = []\n\n            for msg in msgs:\n                self.handle_message(msg)\n\n            if self.keep_printing:\n                print(self.print_char, end='', flush=True)\n                time.sleep(self.print_frequency)\n\n    def handle_message(self, msg: typing.Union[StartPrinting, StopPrinting, ChangePrintBehavior]):\n        if isinstance(msg, StartPrinting):\n            if self.keep_printing:\n                self.messenger.send_error(AlreadyPrintingError())\n            self.keep_printing = True\n\n        elif isinstance(msg, StopPrinting):\n            if not self.keep_printing:\n                self.messenger.send_error(AlreadyNotPrintingError())\n            self.keep_printing = False\n\n        elif isinstance(msg, ChangePrintBehavior):\n            self.print_frequency = msg.print_frequency\n            self.print_char = msg.print_char\n\n        else:\n            # process should die in this case\n            self.messenger.send_error(NotImplementedError(f'Unknown message type: {type(msg)}'))\n\n        self.messenger.send_reply(Receipt())\n\n</code></pre> <pre><code>@dataclasses.dataclass\nclass PrintProcessController:\n    messenger: coproc.PriorityMessenger\n    def start_printing(self):\n        self.messenger.send_request(StartPrinting())\n        return self.messenger.receive_blocking() # wait for receipt\n\n    def stop_printing(self):\n        self.messenger.send_request(StopPrinting())\n        return self.messenger.receive_blocking() # wait for receipt\n\n    def change_behavior(self, print_frequency: int, print_char: str):\n        self.messenger.send_request(ChangePrintBehavior(print_frequency, print_char))\n        return self.messenger.receive_blocking() # wait for receipt\n\nclass Printer:\n\n    def __init__(self, print_frequency: int, print_char: str, start_printing: bool = False):\n        # passed to PrintingProcess when starting\n        self.process_kwargs = dict(\n            print_frequency = print_frequency, \n            print_char = print_char, \n            keep_printing = start_printing\n        )\n        self.resource = coproc.WorkerResource(PrintingProcess)\n\n    def __enter__(self) -&gt; PrintProcessController:\n        self.resource.start(**self.process_kwargs)\n        return PrintProcessController(self.resource.messenger)\n\n    def __exit__(self, *args):\n        self.resource.terminate()\n</code></pre> <pre><code>with Printer(print_frequency=0.05, print_char='x', start_printing=False) as p:\n    print('\\n----')\n    time.sleep(0.2) # shouldnot be printing\n    print('\\n----')\n    p.start_printing()\n    print('\\n----')\n    time.sleep(0.2) # should be printing\n    print('\\n----')\n    p.change_behavior(0.01, 'y')\n    print('\\n----')\n    time.sleep(0.2) # should be printing\n    p.stop_printing()\n    time.sleep(0.2) # should not be printing\n\n    try: # this error is being sent by the printer process\n        p.stop_printing()\n    except AlreadyNotPrintingError:\n        print('Already not printing! oh well.')\n</code></pre> <pre><code>self.keep_printing=False\n\n----\n\n----\n\n----\nxxxxyyyyyyyyyyyyyyyyyy\n----\n\n----\n\n\nNoneType: None\n\n\nAlready not printing! oh well.\n</code></pre>"},{"location":"documentation/messenger_introduction/","title":"Messaging Between Processes","text":""},{"location":"documentation/messenger_introduction/#prioritymessenger-and-multimessenger","title":"<code>PriorityMessenger</code> and <code>MultiMessenger</code>","text":"<p>The <code>coproc</code> messengers are wrappers around standard <code>multiprocessing.Pipe</code> objects that create an interface for exchange between processes. There are two primary messenger types that can be used for communications: <code>PriorityMessenger</code> and <code>MultiMessenger</code>. While they both support the request and channel interfaces, only <code>PriorityMessenger</code> supports priorities, as the name would imply. </p> <p>The diagram below shows how both the host and worker processes maintain separate messengers that allow them to communicate together. While I imagine that some of the messenger features will be most often used on one side or the other (for example, the request/reply interface), the messages are identical.</p> <p></p>"},{"location":"documentation/messenger_introduction/#sending-messages","title":"Sending Messages","text":"<p>Basic communication.</p> <ul> <li> <p><code>send_norequest()</code> sends a message without expecting a reply. This is the most basic method for sending data between processes. Specify <code>channel_id</code> to send to a specific channel (<code>None</code> by default, which is actually a valid channel). The simplest use of messager would be to to send messages back and forth using <code>send_norequest()</code>. This is most similar to <code>pipe.send()</code> and <code>pipe.recv()</code> except that it manages multiple channels (see next section).</p> </li> <li> <p>Channels. Every message is associated with a channel, which can be any hashable object. </p> <ul> <li>You can specify the channel using the <code>channel_id</code> parameter of most send/receive functions, and the default is <code>None</code> - itself a valid, hashable channel id which you may use by default.</li> </ul> </li> <li> <p>Requests. Using special request and reply methods enables the messenger to track the number of requests sent and replies received so that it can wait for replies to a specific set of requests.</p> <ul> <li>The requesting process would use <code>send_request()</code> to send a request, and the other process would use <code>send_reply()</code> so that the requesting process knows that the message is a reply.</li> <li>Note that the request tracking happens on a per-channel basis, so you can send multiple requests on different channels and wait for replies to each set of requests.</li> <li><code>send_request()</code> will send a message while also incrementing the count of requested messages for the given channel.</li> <li><code>send_reply()</code> will send a message while also incrementing the count of received replies for the recipient channel.</li> </ul> </li> <li> <p>Priorities. By default, the <code>PriorityMessenger</code> looks for a <code>priority</code> attribute on any messages being sent, and will sort the messages into a priority queue, rather than a standard fifo queue. If the sent item does not have this attribute, by default it is set to <code>-inf</code>.</p> </li> <li> <p>Special Messages. There are several types of special messages that bypass the channel and priority queue interface - they are handled as soon as the messages are received (which occurs when any receive function is called), prior to placement in the queue.</p> <ul> <li><code>send_error()</code> will send an exception object to the other messenger that will then be raised directly in the recipient process. I recommend using custom exceptions for this behavior.</li> <li><code>send_close_request()</code> will send a message that directly raises a <code>ResourceRequestedClose</code> exception in the recipient process. Catch this exception in your processes to handle a shutdown. You may want to use this in conjunction with the <code>.join()</code> method, which waits for the process to finish.</li> </ul> </li> </ul>"},{"location":"documentation/messenger_introduction/#receiving-messages","title":"Receiving Messages","text":"<p>Any time one of the following receive methods is called, data will be transferred from the <code>multiprocessing.Pipe</code> into the message queue. The following diagram shows the basic flow of data from the pipe to the receive methods.</p> <p></p> <p>The receive method you use depends on the desigred behavior.</p> <ul> <li><code>available()</code> loads data from pipe into the queue, and returns the number of available messages on the specified channel. </li> <li><code>receive_available()</code> calls <code>available()</code> and returns all available messages if there are any. Otherwise, returns an empty list.</li> <li><code>receive_blocking()</code> blocks until a message is received on the specified channel, then returns the message.</li> <li><code>receive_remaining()</code> yields replies on the specified channel until all outstanding requests have been replied to.</li> </ul>"},{"location":"documentation/messenger_introduction/#example-usage","title":"Example Usage","text":"<p>Now I will give some examples for how to use the messenger interface.</p> <pre><code>import sys\nsys.path.append('../')\nimport coproc\n\nimport dataclasses\nimport time\n</code></pre>"},{"location":"documentation/messenger_introduction/#choosing-a-messenger","title":"Choosing a Messenger","text":"<p>While messengers can be used by themselves, they can be managed by <code>WorkerResource</code> objects by passing them to the <code>messenger_type</code> parameter of the constructor. See how <code>WorkerResource</code> creates two messengers: one for the host process and one for the worker process.</p> <pre><code>@dataclasses.dataclass\nclass ExampleProcess:\n    messenger: coproc.PriorityMessenger\n\n    def __call__(self):\n        print(f'process messenger: {self.messenger}')\n\nworker = coproc.WorkerResource(\n    worker_process_type =  ExampleProcess,\n    messenger_type = coproc.PriorityMessenger,\n)\nwith worker as w:\n    time.sleep(1)\n    print(f'resource messenger: {w.messenger}')\n</code></pre> <pre><code>process messenger: PriorityMessenger(pipe=&lt;multiprocessing.connection.Connection object at 0x7f3991f16c10&gt;, queue=PriorityMultiQueue(queues={}), request_ctr=RequestCtr(requests=Counter(), replies=Counter(), sent=Counter(), received=Counter()))\nresource messenger: PriorityMessenger(pipe=&lt;multiprocessing.connection.Connection object at 0x7f394a08f880&gt;, queue=PriorityMultiQueue(queues={}), request_ctr=RequestCtr(requests=Counter(), replies=Counter(), sent=Counter(), received=Counter()))\n</code></pre>"},{"location":"documentation/messenger_introduction/#messenger-interface","title":"Messenger Interface","text":"<p>Now I will give some examples for using the messenger interface.</p>"},{"location":"documentation/messenger_introduction/#sendreceive-and-channels","title":"Send/receive and Channels","text":"<p>In this example you can see how we send and receive the most basic messages messages on two separate channels over the same pipe. We use the <code>send_norequest()</code> method to send data to the other side, and specify the <code>channel_id</code> parameter of most send/receive methods to specify the channel.</p> <pre><code>CHANNEL_A = 1\nCHANNEL_B = 2\n\n@dataclasses.dataclass\nclass EchoProcess1:\n    messenger: coproc.PriorityMessenger\n    def __call__(self):\n        while True:\n            print(f'awaiting messages')\n            self.messenger.await_available()\n            print(f'some messages were found')\n            for data in self.messenger.receive_available(CHANNEL_A):\n                self.messenger.send_norequest(data, CHANNEL_A)\n\n            for data in self.messenger.receive_available(CHANNEL_B):\n                self.messenger.send_norequest(data, CHANNEL_B)\n\n            #data = self.messenger.receive_blocking()\n            #print(f'worker received: {data}')\n            #self.messenger.send_norequest(data)\n\nwith coproc.WorkerResource(EchoProcess1) as w:\n    print(f'{w.messenger.available()=}')\n    print(w.messenger.send_norequest('hello', channel_id=CHANNEL_A))\n    print(w.messenger.send_norequest('hi', channel_id=CHANNEL_B))\n    time.sleep(0.1) # wait for process to return it\n\n    print(f'{w.messenger.available()=}')\n    print(f'{w.messenger.receive_blocking(CHANNEL_A)=}')\n    print(f'{w.messenger.receive_blocking(CHANNEL_B)=}')\n</code></pre> <pre><code>awaiting messages\nsome messages were found\nawaiting messages\nw.messenger.available()=0\nNone\nNone\nw.messenger.available()=0\nw.messenger.receive_blocking(CHANNEL_A)='hello'\nw.messenger.receive_blocking(CHANNEL_B)='hi'\n</code></pre>"},{"location":"documentation/messenger_introduction/#request-interface","title":"Request Interface","text":"<p>In this example, I use <code>send_request()</code> and <code>send_reply()</code> to send and receive messages synchronously. The messenger will track the number of requests sent, and we can use <code>receive_remaining()</code> to wait for all expected replies to be received.</p> <pre><code>@dataclasses.dataclass\nclass EchoProcess2(coproc.BaseWorkerProcess):\n    def __call__(self):\n        while True:\n            data = self.messenger.receive_blocking()\n            self.messenger.send_reply(data)\n\nwith coproc.WorkerResource(EchoProcess2) as w:\n    print(f'{w.messenger.remaining()=}')\n    print(f'{w.messenger.send_request(\"hello\")=}')\n    print(f'{w.messenger.remaining()=}')\n    time.sleep(0.1)\n    print(f'{w.messenger.receive_blocking()=}')\n    print(f'{w.messenger.remaining()=}')\n\n    print(f'sending {[w.messenger.send_request(i) for i in range(3)]}')\n    print(f'{w.messenger.remaining()=}')\n    for d in w.messenger.receive_remaining():\n        print(d)\n</code></pre> <pre><code>w.messenger.remaining()=0\nw.messenger.send_request(\"hello\")=None\nw.messenger.remaining()=1\nw.messenger.receive_blocking()='hello'\nw.messenger.remaining()=0\nsending [None, None, None]\nw.messenger.remaining()=3\n0\n1\n2\n</code></pre>"},{"location":"documentation/messenger_introduction/#priority-interface","title":"Priority Interface","text":"<p>We can set the priority of messages by adding a <code>priority</code> attribute to the message - we used simple wrapper objects here to accomplish that. Notice that the process accesses the higher priority objects first.</p> <p>Note that the default priority is <code>-inf</code>, so any message without a priority will be sent to the back of the queue. In this example, we send messages with different priorities and see how they are received in order.</p> <pre><code>@dataclasses.dataclass\nclass PrintProcess(coproc.BaseWorkerProcess):\n    def __call__(self):\n        while True:\n            for data in self.messenger.receive_available():\n                #self.messenger.send_reply(data)\n                print(data)\n            time.sleep(1)\n\n@dataclasses.dataclass\nclass HighPriorityMessage:\n    text: str\n    priority: int = 0 # lower is more improtant\n\n@dataclasses.dataclass\nclass LowPriorityMessage:\n    text: str\n    priority: int = 1 # lower is more improtant\n\nwith coproc.WorkerResource(PrintProcess, coproc.PriorityMessenger) as w:\n    for i in range(3):\n        w.messenger.send_norequest(LowPriorityMessage(f'low {i}'))\n        w.messenger.send_norequest(HighPriorityMessage(f'high {i}'))\n\n    time.sleep(0.1) # wait for process to finish. Should I use join here?\n</code></pre> <pre><code>HighPriorityMessage(text='high 0', priority=0)\nHighPriorityMessage(text='high 1', priority=0)\nHighPriorityMessage(text='high 2', priority=0)\nLowPriorityMessage(text='low 0', priority=1)\nLowPriorityMessage(text='low 1', priority=1)\nLowPriorityMessage(text='low 2', priority=1)\n</code></pre>"},{"location":"documentation/messenger_introduction/#special-messages","title":"Special Messages","text":"<p>In this last example I demonstrate use of the special messages. The <code>send_error()</code> method sends an exception object to the other process, which will be raised directly in the other process. The <code>send_close_request()</code> method sends a message that raises a <code>ResourceRequestedClose</code> exception in the other process. This is useful for shutting down the process.</p> <pre><code>@dataclasses.dataclass\nclass PrintProcess2(coproc.BaseWorkerProcess):\n    def __call__(self):\n        while True:\n            try:\n                message = self.messenger.await_available()\n                results = self.messenger.receive_available()\n            except coproc.ResourceRequestedClose as e:\n                self.messenger.send_error(ValueError('process was closed successfully'))\n                break # exits the process naturally\n            for data in results:\n                print(data)\n\nwith coproc.WorkerResource(PrintProcess2) as w:\n    w.messenger.send_norequest('message 1')\n    w.messenger.send_close_request()\n\n    try:\n        w.messenger.await_available()\n    except ValueError as e:\n        print('successfully caught value error sent from process')\n\n    time.sleep(0.1) # wait for process to finish. Should I use join here?\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"/tmp/ipykernel_1047367/3808203598.py\", line 6, in __call__\n    message = self.messenger.await_available()\n  File \"/DataDrive/projects/coproc/examples/../coproc/messenger/multimessenger.py\", line 121, in await_available\n    self._receive_and_handle()\n  File \"/DataDrive/projects/coproc/examples/../coproc/messenger/multimessenger.py\", line 133, in _receive_and_handle\n    self._handle_message(msg)\n  File \"/DataDrive/projects/coproc/examples/../coproc/messenger/multimessenger.py\", line 147, in _handle_message\n    raise ResourceRequestedClose(f'Resource requested that this process close.')\ncoproc.messenger.exceptions.ResourceRequestedClose: Resource requested that this process close.\n\n\nsuccessfully caught value error sent from process\n</code></pre>"},{"location":"documentation/monitor_introduction/","title":"Introduction to <code>Monitor</code>","text":"<p>The <code>Monitor</code> object is used to create a concurrent process that will monitor the host process memory and cpu usage, record notes, and plot current progress as needed.</p> <pre><code>import sys\nsys.path.append('..')\nimport coproc\n</code></pre>"},{"location":"documentation/monitor_introduction/#receiving-stats-client-side","title":"Receiving Stats Client-side","text":"<p>In this example, I open the monitor and it runs while the inner code is executing. The monitor routinely checks for memory usage, and every so often sends a note to the monitor that is recorded. Uing <code>get_stats()</code> we can retrieve the statistics and plot it using <code>get_stats_plot()</code>. Notice that the notes appear in the figure.</p> <pre><code>import time\nimport tqdm\nwith coproc.Monitor(snapshot_seconds=0.01) as m:\n\n    l = list()\n    for i in tqdm.tqdm(range(int(1e6)), ncols=80):\n        l.append(i)\n        if i &gt; 0 and i % int(3e5) == 0:\n            m.add_note('dump', 'dumping all memory', do_print=True)\n            l = list() # dump memory\n\n            stats = m.get_stats()\n            p = stats.plot_memory(font_size=5)\n            p.draw()\n</code></pre> <pre><code>['BaseWorkerProcess', 'ChannelID', 'Close', 'CloseRequestMessage', 'DataMessage', 'EncounteredErrorMessage', 'LazyPool', 'MemoryInfoNotAvailableError', 'Message', 'MessageFromProcess', 'MessageFromProcessType', 'MessageNotRecognizedError', 'MessageToProcess', 'MessageToProcessType', 'MessageType', 'Monitor', 'MonitorMessage', 'MonitorMessengerInterface', 'MonitorWorkerProcess', 'MultiMessenger', 'MultiQueue', 'Note', 'Pool', 'PriorityMessenger', 'PriorityMultiQueue', 'PriorityQueue', 'RecvPayloadType', 'ReplyData', 'RequestSaveMemoryFigureMessage', 'RequestStatsMessage', 'ResourceRequestedClose', 'SendPayloadType', 'Stat', 'StatsDataMessage', 'StatsResult', 'SubmitData', 'SubmitNoteMessage', 'UpdateChildProcessesMessage', 'UserfuncError', 'WorkerIsAlreadyAliveError', 'WorkerIsAlreadyDeadError', 'WorkerResource', 'WorkerResourcePool', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'annotations', 'baseworkerprocess', 'basicqueue', 'dataclasses', 'datetime', 'dynamicmapprocess', 'enum', 'exceptions', 'lazypool', 'messages', 'messenger', 'monitor', 'monitormessenger', 'monitorprocess', 'multimessenger', 'multiprocessing', 'multiqueue', 'os', 'pathlib', 'pd', 'plotnine', 'plt', 'pool', 'prioritymessenger', 'prioritymultiqueue', 'priorityqueue', 'psutil', 'queue', 'requestctr', 'staticmapprocess', 'statsresult', 'time', 'typing', 'workerresource', 'workerresourcepool']\n\n\n  0%|                                               | 0/1000000 [00:00&lt;?, ?it/s] 18%|\u2588\u2588\u2588\u2588\u2588\u258e                       | 183064/1000000 [00:00&lt;00:00, 1830550.09it/s]\n\ndump; new_note.details='dumping all memory'\n\n\n 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588         | 700838/1000000 [00:00&lt;00:00, 882974.08it/s]\n\ndump; new_note.details='dumping all memory'\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000000/1000000 [00:01&lt;00:00, 951835.92it/s]\n\n\ndump; new_note.details='dumping all memory'\n</code></pre> <p></p> <p></p> <p></p>"},{"location":"documentation/pool_benchmark/","title":"Benchmark Comparison <code>Pool</code>","text":"<p>Where <code>coproc</code> was designed for situations where you want to maintain persistent, stateful processes, the <code>conproc.Pool</code> interface essentially emulates the behavior of <code>multiprocessing.Pool</code> in order to benchmark the performance of the underlying <code>WorkerResource</code> and <code>PriorityMessenger</code> systems.</p> <p>RESULTS: similar performance except when thread tasks are small and numerous, in which case <code>coproc</code> is much slower.</p> <pre><code>import sys\nsys.path.append('..')\nimport coproc\nimport multiprocessing\n</code></pre> <pre><code>import time\ndef square(v):\n    time.sleep(0.05)\n    return v**2\n\ndef map_square(vs, pool):\n    return pool.map(square, vs)\n\nn = 3\nvalues = list(range(100))\ncp = coproc.LazyPool(n)\n\n#map_square(values, cp)\n#map_square(values, cp)\n#map_square(values, cp)\n#map_square(values, cp)\n#%timeit map_square(values, cp)\nwith coproc.Pool(n) as p:\n    %time map_square(values, cp)\n    %time map_square(values, p)\n</code></pre> <pre><code>CPU times: user 1.59 s, sys: 108 ms, total: 1.69 s\nWall time: 1.74 s\nCPU times: user 1.55 s, sys: 116 ms, total: 1.66 s\nWall time: 1.71 s\n</code></pre>"}]}